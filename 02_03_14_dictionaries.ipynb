{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Image Classification Models\n",
    "\n",
    "In the field of artificial intelligence, particularly in computer vision, image classification is a fundamental task. It involves assigning a label or category to an input image based on its visual content. The success of image classification tasks relies heavily on the architecture of the models used. Among the various types of models, Convolutional Neural Networks (CNNs) have proven to be highly effective. CNNs are designed to automatically and adaptively learn spatial hierarchies of features from input images through a series of layers.\n",
    "\n",
    "In this section, we will discuss several prominent CNN architectures that have significantly advanced the field of image classification. These models include AlexNet, VGG, ResNet, and MobileNet. Each of these models has unique characteristics and innovations that make them suitable for different applications and environments.\n",
    "\n",
    "### Convolutional Neural Networks (CNNs)\n",
    "**Convolutional Neural Networks (CNNs)** are a class of deep learning algorithms that are particularly well-suited for image recognition and classification tasks. CNNs automatically and adaptively learn spatial hierarchies of features from input images. They consist of multiple layers, such as convolutional layers, pooling layers, and fully connected layers, which help in detecting edges, textures, shapes, and more complex features. CNNs have been the foundation for many state-of-the-art models in computer vision.\n",
    "\n",
    "### AlexNet\n",
    "**AlexNet** is a pioneering convolutional neural network (CNN) architecture that won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. Developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, AlexNet consists of eight layers: five convolutional layers followed by three fully connected layers. It introduced the use of ReLU activation functions, dropout layers to prevent overfitting, and data augmentation techniques to improve model generalization.\n",
    "\n",
    "### VGG (Visual Geometry Group)\n",
    "**VGG** refers to a series of convolutional neural network models developed by the Visual Geometry Group at the University of Oxford. The VGG architectures, such as VGG-16 and VGG-19, are known for their simplicity and uniform architecture. They use 3x3 convolutional layers stacked on top of each other, with increasing depth. This design allows the network to capture complex features while keeping the number of parameters manageable. VGG models achieved high accuracy on the ImageNet dataset and are widely used as feature extractors.\n",
    "\n",
    "### ResNet (Residual Networks)\n",
    "**ResNet**, short for Residual Networks, is a deep learning model architecture introduced by Kaiming He and his colleagues at Microsoft Research. It addresses the issue of vanishing gradients in deep networks by introducing \"residual connections,\" which are shortcuts that skip one or more layers. This allows the network to learn residual functions with reference to the layer inputs, which significantly improves training efficiency and accuracy. ResNet models come in various depths, such as ResNet-50, ResNet-101, and ResNet-152, indicating the number of layers in the network.\n",
    "\n",
    "### MobileNet\n",
    "**MobileNet** is a family of lightweight deep learning models designed for efficient image classification on mobile and embedded devices. Developed by Google, MobileNet models use depthwise separable convolutions to reduce the number of parameters and computational cost. This makes them suitable for real-time applications on devices with limited resources. MobileNet architectures include versions like MobileNetV1, V2, and V3, each providing improvements in accuracy and efficiency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Define and Manipulate a Dictionary for Model Accuracies\n",
    "\n",
    "### Part 1: Define the Dictionary\n",
    "Define a dictionary named `model_accuracies` that contains this data:\n",
    "\n",
    "|  **Keys** | **Values**  |\n",
    "|---|---|\n",
    "|  ResNet | 0.91  |\n",
    "|  AlexNet | 0.85  |\n",
    "|  VGG |  0.88 |\n",
    "|  Inception | 0.92  |\n",
    "\n",
    "### Part 2: Calculate the Average Accuracy\n",
    "Write code to calculate the average accuracy of the models in the `model_accuracies` dictionary and store it in the variable `average_accuracy`.\n",
    "\n",
    "### Part 3: Find the Best Model\n",
    "Write code to find the model with the highest accuracy and store its name in the variable `best_model`.\n",
    "\n",
    "### Part 4: Add a New Model\n",
    "Add a new model named `MobileNet` with an accuracy of `0.89` to the `model_accuracies` dictionary.\n",
    "\n",
    "### Instructions:\n",
    "1. Define a dictionary `model_accuracies` where the key is the name of an image classification model (a string) and the associated value is its accuracy (a float).\n",
    "2. Calculate the average accuracy of the models.\n",
    "3. Find the model with the highest accuracy.\n",
    "4. Add a new model to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice work defining the dictionary!\n",
      "\n",
      "Nice work calculating the average accuracy!\n",
      "\n",
      "Nice work finding the best model!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 1: Define the dictionary\n",
    "# TODO: replace None with appropriate code\n",
    "# Define a dictionary, `model_accuracies`, that provides information\n",
    "# on the accuracies of different image classification models. \n",
    "# The key is the name of a model (a string), and the associated value \n",
    "# is its accuracy (a float).\n",
    "#   Key      |   Value\n",
    "# ResNet     |   0.91\n",
    "# AlexNet    |   0.85\n",
    "# VGG        |   0.88\n",
    "# Inception  |   0.92\n",
    "model_accuracies = {\n",
    "    \"ResNet\": 0.91,\n",
    "    \"AlexNet\": 0.85,\n",
    "    \"VGG\": 0.88,\n",
    "    \"Inception\": 0.92\n",
    "}\n",
    "\n",
    "# Part 2: Calculate the average accuracy\n",
    "# TODO: replace None with appropriate code\n",
    "average_accuracy = sum(model_accuracies.values()) / len(model_accuracies)\n",
    "\n",
    "# Part 3: Find the best model\n",
    "# TODO: replace None with appropriate code\n",
    "best_model = max(model_accuracies, key=model_accuracies.get)\n",
    "\n",
    "# Part 4: Add a new model\n",
    "# TODO: replace None with appropriate code\n",
    "# Add the model MobileNet with an accuracy of 0.89\n",
    "new_model = 'MobileNet'\n",
    "new_accuracy = 0.89\n",
    "\n",
    "# Add the new model to the dictionary\n",
    "model_accuracies[new_model] = new_accuracy\n",
    "\n",
    "### Notebook grading\n",
    "model_accuracies_solution = {\n",
    "    \"ResNet\": 0.91, \n",
    "    \"AlexNet\": 0.85,\n",
    "    \"VGG\": 0.88,\n",
    "    \"Inception\": 0.92,\n",
    "    \"MobileNet\": 0.89\n",
    "}\n",
    "\n",
    "if model_accuracies == model_accuracies_solution:\n",
    "    print(\"Nice work defining the dictionary!\\n\")\n",
    "\n",
    "average_accuracy_solution = 0.89\n",
    "if average_accuracy == average_accuracy_solution:\n",
    "    print(\"Nice work calculating the average accuracy!\\n\")\n",
    "else:\n",
    "    print(f\"Double check your average accuracy calculation. It should be {average_accuracy_solution}.\")\n",
    "\n",
    "best_model_solution = 'Inception'\n",
    "if best_model == best_model_solution:\n",
    "    print(\"Nice work finding the best model!\\n\")\n",
    "else:\n",
    "    print(f\"Double check your best model calculation. It should be {best_model_solution}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
