{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Model Accuracy Guess\n",
    "\n",
    "In this exercise, you'll compare a predicted accuracy to an actual accuracy and provide feedback on whether the predicted accuracy is too low, too high, or matches the actual accuracy.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "You have an actual model accuracy stored in a variable called `actual_accuracy`. Another user provides a predicted accuracy called `predicted_accuracy`. By comparing `predicted_accuracy` to `actual_accuracy`, inform the user if their prediction is too high, too low, or correct.\n",
    "\n",
    "**Example Input**:\n",
    "```python\n",
    "actual_accuracy = 0.85  # replace with actual accuracy\n",
    "predicted_accuracy = 0.80  # replace with predicted accuracy\n",
    "```\n",
    "\n",
    "**Instructions**:\n",
    "1. Compare `predicted_accuracy` to `actual_accuracy`.\n",
    "2. Inform the user if their prediction is too high, too low, or correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job!\n"
     ]
    }
   ],
   "source": [
    "# Actual and predicted accuracies\n",
    "actual_accuracy = 0.85  # replace with actual accuracy\n",
    "predicted_accuracy = 0.80  # replace with predicted accuracy\n",
    "\n",
    "# Compare predicted accuracy to actual accuracy\n",
    "if predicted_accuracy < actual_accuracy:\n",
    "    result = \"Oops! Your prediction was too low.\"\n",
    "elif predicted_accuracy > actual_accuracy:\n",
    "    result = \"Oops! Your prediction was too high.\"\n",
    "else:\n",
    "    result = \"Nice! Your prediction matched the actual accuracy!\"\n",
    "\n",
    "### Notebook grading\n",
    "def get_solution(actual_accuracy, predicted_accuracy):\n",
    "    if predicted_accuracy < actual_accuracy:\n",
    "        return \"Oops! Your prediction was too low.\"\n",
    "    elif predicted_accuracy > actual_accuracy:\n",
    "        return \"Oops! Your prediction was too high.\"\n",
    "    else:\n",
    "        return \"Nice! Your prediction matched the actual accuracy!\"\n",
    "\n",
    "if result == get_solution(actual_accuracy, predicted_accuracy):\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Try again. That doesn't look like the expected answer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Compute Resource Cost Calculation\n",
    "\n",
    "In this exercise, you'll calculate the total cost of running a machine learning model training session based on the cloud provider used. Different providers have different cost rates.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Depending on the cloud provider, you need to apply the appropriate cost rate to the computation cost. The providers and their rates are as follows: AWS (7.5%), Azure (9.5%), and GCP (8.9%). Use this information to calculate the total cost of running the training session based on the provider and the initial computation cost.\n",
    "\n",
    "**Example Input**:\n",
    "```python\n",
    "provider = \"AWS\"  # Either \"AWS\", \"Azure\", or \"GCP\"\n",
    "computation_cost = 1000  # amount of computation cost\n",
    "```\n",
    "\n",
    "**Instructions**:\n",
    "1. Use the provider to determine the cost rate.\n",
    "2. Calculate the total cost based on the computation cost and the cost rate.\n",
    "3. Inform the user of the total cost based on their provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job!\n"
     ]
    }
   ],
   "source": [
    "# Provider and computation cost\n",
    "provider = \"AWS\"  # Either \"AWS\", \"Azure\", or \"GCP\"\n",
    "computation_cost = 1000  # amount of computation cost\n",
    "\n",
    "# Determine the cost rate based on the provider and calculate the total cost\n",
    "if provider == \"AWS\":\n",
    "    cost_rate = 0.075\n",
    "    total_cost = computation_cost * (1 + cost_rate)\n",
    "    result = f\"Since you are using {provider}, your total cost is ${total_cost:.2f}.\"\n",
    "elif provider == \"Azure\":\n",
    "    cost_rate = 0.095\n",
    "    total_cost = computation_cost * (1 + cost_rate)\n",
    "    result = f\"Since you are using {provider}, your total cost is ${total_cost:.2f}.\"\n",
    "elif provider == \"GCP\": \n",
    "    cost_rate = 0.089\n",
    "    total_cost = computation_cost * (1 + cost_rate)\n",
    "    result = f\"Since you are using {provider}, your total cost is ${total_cost:.2f}.\"\n",
    "else:\n",
    "    \"Provider not recognized.\"\n",
    "\n",
    "### Notebook grading\n",
    "def get_solution(provider, computation_cost):\n",
    "    if provider == 'AWS':\n",
    "        cost_rate = .075\n",
    "        total_cost = computation_cost * (1 + cost_rate)\n",
    "        result = \"Since you are using {}, your total cost is ${:.2f}.\".format(provider, total_cost)\n",
    "    elif provider == 'Azure':\n",
    "        cost_rate = .095\n",
    "        total_cost = computation_cost * (1 + cost_rate)\n",
    "        result = \"Since you are using {}, your total cost is ${:.2f}.\".format(provider, total_cost)\n",
    "    elif provider == 'GCP':\n",
    "        cost_rate = .089\n",
    "        total_cost = computation_cost * (1 + cost_rate)\n",
    "        result = \"Since you are using {}, your total cost is ${:.2f}.\".format(provider, total_cost)\n",
    "    else:\n",
    "        result = \"Provider not recognized.\"\n",
    "    return result\n",
    "\n",
    "if result == get_solution(provider, computation_cost):\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"Oops! That doesn't look like the expected answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
