{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Tokenizing a Sentence\n",
    "\n",
    "**Problem Statement**:\n",
    "Given a sentence, tokenize it into individual words and print each word on a new line. This is a common step in NLP to prepare text data for further analysis.\n",
    "\n",
    "**Instructions**:\n",
    "1. Create a list of words from a sentence.\n",
    "2. Use a for loop to print each word on a new line.\n",
    "\n",
    "**Example Input**:\n",
    "```python\n",
    "sentence = \"the quick brown fox jumped over the lazy dog\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "quick\n",
      "brown\n",
      "fox\n",
      "jumped\n",
      "over\n",
      "the\n",
      "lazy\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "# Define the sentence\n",
    "sentence = \"the quick brown fox jumped over the lazy dog\"\n",
    "\n",
    "# Tokenize the sentence into words\n",
    "words = sentence.split()\n",
    "\n",
    "# Print each word on a new line\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Batching Data for Model Training\n",
    "\n",
    "In this exercise, you will simulate the process of batching data for model training, where data is processed in fixed-size batches.\n",
    "\n",
    "**Problem Statement**:\n",
    "Given a dataset, divide it into batches of a specified size and print each batch. This simulates the process of batching data during model training.\n",
    "\n",
    "**Instructions**:\n",
    "1. Create a list of numbers from 1 to 30.\n",
    "2. Use a for loop to divide the list into batches of 5 items each and print each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: [1, 2, 3, 4, 5]\n",
      "Batch 2: [6, 7, 8, 9, 10]\n",
      "Batch 3: [11, 12, 13, 14, 15]\n",
      "Batch 4: [16, 17, 18, 19, 20]\n",
      "Batch 5: [21, 22, 23, 24, 25]\n",
      "Batch 6: [26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "data = list(range(1, 31))\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 5\n",
    "\n",
    "# Process the data in batches\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i + batch_size]\n",
    "    print(f\"Batch {i // batch_size + 1}: {batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
